{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T08:46:43.174934200Z",
     "start_time": "2024-04-29T08:46:41.514149700Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path as osp\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, HeteroData\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './children_genre/raw/goodreads_reviews_children.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 110\u001B[0m\n\u001B[1;32m    106\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave([data], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessed_paths[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 110\u001B[0m     \u001B[43mGoodreads_children_genre\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[2], line 12\u001B[0m, in \u001B[0;36mGoodreads_children_genre.__init__\u001B[0;34m(self, root)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, root: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 12\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessed_paths[\u001B[38;5;241m0\u001B[39m], data_cls\u001B[38;5;241m=\u001B[39mHeteroData)\n",
      "File \u001B[0;32m~/.virtualenvs/Python_Programming/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:81\u001B[0m, in \u001B[0;36mInMemoryDataset.__init__\u001B[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     74\u001B[0m     root: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     79\u001B[0m     force_reload: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     80\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 81\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpre_transform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpre_filter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mforce_reload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data: Optional[BaseData] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mslices: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, Tensor]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/Python_Programming/lib/python3.10/site-packages/torch_geometric/data/dataset.py:115\u001B[0m, in \u001B[0;36mDataset.__init__\u001B[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001B[0m\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_download()\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhas_process:\n\u001B[0;32m--> 115\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/Python_Programming/lib/python3.10/site-packages/torch_geometric/data/dataset.py:260\u001B[0m, in \u001B[0;36mDataset._process\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    257\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProcessing...\u001B[39m\u001B[38;5;124m'\u001B[39m, file\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39mstderr)\n\u001B[1;32m    259\u001B[0m fs\u001B[38;5;241m.\u001B[39mmakedirs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessed_dir, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 260\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    262\u001B[0m path \u001B[38;5;241m=\u001B[39m osp\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessed_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpre_transform.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    263\u001B[0m fs\u001B[38;5;241m.\u001B[39mtorch_save(_repr(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_transform), path)\n",
      "Cell \u001B[0;32mIn[2], line 54\u001B[0m, in \u001B[0;36mGoodreads_children_genre.process\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     41\u001B[0m final_genre_book \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     42\u001B[0m genres \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhistory, historical fiction, biography\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     43\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchildren\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     44\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mromance\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     51\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfantasy, paranormal\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m9\u001B[39m,\n\u001B[1;32m     52\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNone\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m10\u001B[39m}\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f:\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(line)\n",
      "File \u001B[0;32m~/.virtualenvs/Python_Programming/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    322\u001B[0m     )\n\u001B[0;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './children_genre/raw/goodreads_reviews_children.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os.path as osp\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, HeteroData\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Goodreads_crime_genre(InMemoryDataset):\n",
    "    def __init__(self, root: str) -> None:\n",
    "        super().__init__(root)\n",
    "        self.load(self.processed_paths[0], data_cls=HeteroData)\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self) -> str:\n",
    "        return osp.join(self.root, 'crime_genre', 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self) -> str:\n",
    "        return osp.join(self.root, 'crime_genre', 'processed')\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        file_names = [\n",
    "            'node-feat', 'node-label', 'relations', 'split',\n",
    "            'num-node-dict.csv.gz'\n",
    "        ]\n",
    "\n",
    "        return file_names\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "\n",
    "    def process(self) -> None:\n",
    "        path = osp.join(self.raw_dir, 'goodreads_reviews_crime.json')\n",
    "        genre_path = osp.join(self.raw_dir, 'goodreads_book_genres_initial.json')\n",
    "\n",
    "        final_data = []\n",
    "        final_genre_book = {}\n",
    "        genres = {'history, historical fiction, biography': 0,\n",
    "                  'children': 1,\n",
    "                  'romance': 2,\n",
    "                  'comics, graphic': 3,\n",
    "                  'non-fiction': 4,\n",
    "                  'mystery, thriller, crime': 5,\n",
    "                  'poetry': 6,\n",
    "                  'young-adult': 7,\n",
    "                  'fiction': 8,\n",
    "                  'fantasy, paranormal': 9,\n",
    "                  'None': 10}\n",
    "\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                final_data.append(data)\n",
    "\n",
    "        with open(genre_path) as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                main_genre = max(data['genres'], key=data['genres'].get) if data['genres'] else 'None'\n",
    "                final_genre_book[data['book_id']] = genres[main_genre]\n",
    "        \n",
    "        user_id2idx = {}\n",
    "        book_id2idx = {}\n",
    "        edge_index_user_book = []\n",
    "        edge_index_book_genre = []\n",
    "        edge_label = []\n",
    "\n",
    "        for item in tqdm(final_data):\n",
    "            user_id = item['user_id']\n",
    "            book_id = item['book_id']\n",
    "\n",
    "            # user book\n",
    "            if user_id not in user_id2idx:\n",
    "                user_id2idx[user_id] = len(user_id2idx)\n",
    "            if book_id not in book_id2idx:\n",
    "                book_id2idx[book_id] = len(book_id2idx)\n",
    "\n",
    "            # user-review-book edge, book-description-genre edge\n",
    "            edge_index_user_book.append([user_id2idx[user_id], book_id2idx[book_id]])\n",
    "\n",
    "            # edge label (rating)\n",
    "            edge_label.append(item['rating'])\n",
    "\n",
    "        for book_id, genre in tqdm(final_genre_book.items()):\n",
    "            if book_id in book_id2idx:\n",
    "                edge_index_book_genre.append([book_id2idx[book_id], genre])\n",
    "\n",
    "        # load to heterodata\n",
    "        num_users = len(user_id2idx)\n",
    "        num_books = len(book_id2idx)\n",
    "\n",
    "        data = HeteroData()\n",
    "        data['user'].x = torch.nn.init.xavier_uniform_(torch.Tensor(num_users, 64))\n",
    "        data['book'].x = torch.nn.init.xavier_uniform_(torch.Tensor(num_books, 64))\n",
    "        data['genre'].x = torch.nn.init.xavier_uniform_(torch.Tensor(len(genres), 64))\n",
    "\n",
    "        data['user', 'review', 'book'].edge_index = torch.tensor(edge_index_user_book,\n",
    "                                                                  dtype=torch.long).t().contiguous()\n",
    "        data['book', 'description', 'genre'].edge_index = torch.tensor(edge_index_book_genre,\n",
    "                                                                      dtype=torch.long).t().contiguous()\n",
    "        data['user', 'review', 'book'].edge_label = torch.tensor(edge_label)\n",
    "\n",
    "        self.save([data], self.processed_paths[0])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Goodreads_crime_genre(root='.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T09:40:25.809300800Z",
     "start_time": "2024-04-29T09:40:25.366523800Z"
    }
   },
   "id": "c3ad34029c78a4f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f4fe3277e8a1ef33"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
